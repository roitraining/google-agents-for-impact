{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install google-cloud-aiplatform[adk,agent_engines] google-auth google-genai httpx beautifulsoup4 --quiet --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ5mgiXbL2l0",
        "outputId": "d298ec4a-63cd-4d44-b749-ee5566d53a8f"
      },
      "id": "tZ5mgiXbL2l0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.6/245.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wchKoO57Sn5U",
        "outputId": "f50c2bcf-8286-4ecb-b688-2185037a9c0c"
      },
      "id": "wchKoO57Sn5U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup Project and Vertex AI\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "\n",
        "STAGING_BUCKET = \"gs://dsf345gjt\"\n",
        "\n",
        "# Initialize the Vertex AI SDK\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "MODEL = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg6HAyzqSstq",
        "outputId": "dcce86b5-35c7-428a-bf0b-fcdaa8a5f463"
      },
      "id": "xg6HAyzqSstq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qwiklabs-gcp-01-e87a8593b193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title These ENV variables are used by Gemini Later\n",
        "import os\n",
        "\n",
        "# Tell google-genai to use Vertex AI and where\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"true\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION"
      ],
      "metadata": {
        "id": "C6qKIPLqUTB3"
      },
      "id": "C6qKIPLqUTB3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "ZzCZtFUfR8FBFuhQqx2TCWG9",
      "metadata": {
        "tags": [],
        "id": "ZzCZtFUfR8FBFuhQqx2TCWG9"
      },
      "source": [
        "# @title Set BigQuery Variables\n",
        "DATASET_NAME = \"fda_dataset\"\n",
        "DOWNLOAD_URL = \"https://fdc.nal.usda.gov/fdc-datasets/FoodData_Central_foundation_food_csv_2025-04-24.zip\"\n",
        "EXTRACT_DIR = \"fooddata_csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download and Unzip Data File\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# --- Config ---\n",
        "url = DOWNLOAD_URL\n",
        "zip_filename = \"fooddata.zip\"\n",
        "extract_dir = EXTRACT_DIR  # expects EXTRACT_DIR to be defined in a previous cell\n",
        "\n",
        "# --- Always start from scratch ---\n",
        "if os.path.exists(zip_filename):\n",
        "    try:\n",
        "        os.remove(zip_filename)\n",
        "        print(f\"Removed existing zip: {zip_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: could not remove existing zip ({zip_filename}): {e}\")\n",
        "\n",
        "if os.path.isdir(extract_dir):\n",
        "    try:\n",
        "        shutil.rmtree(extract_dir)\n",
        "        print(f\"Removed existing directory: {extract_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: could not remove existing directory ({extract_dir}): {e}\")\n",
        "\n",
        "# --- Download fresh zip ---\n",
        "print(\"Downloading dataset...\")\n",
        "with requests.get(url, stream=True, timeout=60) as response:\n",
        "    response.raise_for_status()\n",
        "    with open(zip_filename, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1 MB chunks\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# --- Extract into a fresh directory ---\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(\"Extraction complete.\")\n",
        "\n",
        "# --- List all extracted files ---\n",
        "print(\"Extracted files:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for filename in sorted(files):\n",
        "        print(os.path.join(root, filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnLeDfRzsKg7",
        "outputId": "e86fcf3c-5328-44bb-d51c-83f719024bab"
      },
      "id": "CnLeDfRzsKg7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed existing zip: fooddata.zip\n",
            "Removed existing directory: fooddata_csv\n",
            "Downloading dataset...\n",
            "Download complete.\n",
            "Extraction complete.\n",
            "Extracted files:\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/Download API Field Descriptions.xlsx\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/acquisition_samples.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/agricultural_samples.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_attribute.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_attribute_type.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_calorie_conversion_factor.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_category.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_component.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_nutrient.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_nutrient_conversion_factor.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_portion.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_protein_conversion_factor.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_update_log_entry.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/foundation_food.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/input_food.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method_code.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method_nutrient.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/market_acquisition.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/measure_unit.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/nutrient.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sample_food.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sub_sample_food.csv\n",
            "fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sub_sample_result.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save CSV files to BigQuery\n",
        "import os\n",
        "import glob\n",
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import NotFound, GoogleAPICallError, BadRequest\n",
        "\n",
        "# Where you extracted the USDA CSVs (expects EXTRACT_DIR set earlier)\n",
        "BASE_DIR = EXTRACT_DIR\n",
        "MAX_BAD_RECORDS = 100  # <-- allow up to 100 problematic rows per file\n",
        "\n",
        "# Try to find the inner folder automatically (e.g., FoodData_Central_foundation_food_csv_2025-04-24)\n",
        "subdirs = [d for d in glob.glob(os.path.join(BASE_DIR, \"*\")) if os.path.isdir(d)]\n",
        "DATA_DIR = subdirs[0] if subdirs else BASE_DIR\n",
        "\n",
        "print(\"Using data directory:\", DATA_DIR)\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset_ref = bigquery.DatasetReference(PROJECT_ID, DATASET_NAME)\n",
        "\n",
        "# Ensure the dataset exists (create if it doesn't)\n",
        "try:\n",
        "    client.get_dataset(dataset_ref)\n",
        "    print(f\"Dataset {PROJECT_ID}.{DATASET_NAME} exists.\")\n",
        "except NotFound:\n",
        "    ds = bigquery.Dataset(dataset_ref)\n",
        "    ds.location = \"US\"  # change if needed\n",
        "    client.create_dataset(ds)\n",
        "    print(f\"Created dataset {PROJECT_ID}.{DATASET_NAME} in location {ds.location}.\")\n",
        "\n",
        "# Load config for CSVs\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    autodetect=True,                         # Let BigQuery infer schema\n",
        "    skip_leading_rows=1,                     # Header row\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "    field_delimiter=\",\",\n",
        "    quote_character='\"',\n",
        "    allow_quoted_newlines=True,\n",
        "    encoding=\"UTF-8\",\n",
        "    max_bad_records=MAX_BAD_RECORDS,         # <-- tolerate up to N bad rows\n",
        "    ignore_unknown_values=True,            # (Optional) tolerate extra columns\n",
        ")\n",
        "\n",
        "# Iterate over all CSV files and load each into a table named after the file (minus .csv)\n",
        "csv_paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.csv\")))\n",
        "if not csv_paths:\n",
        "    raise FileNotFoundError(f\"No CSV files found in {DATA_DIR}\")\n",
        "\n",
        "summary = []\n",
        "failures = []\n",
        "\n",
        "for csv_path in csv_paths:\n",
        "    table_name = os.path.splitext(os.path.basename(csv_path))[0]\n",
        "    table_ref = dataset_ref.table(table_name)\n",
        "    print(f\"\\nLoading {csv_path} -> {PROJECT_ID}.{DATASET_NAME}.{table_name}\")\n",
        "\n",
        "    try:\n",
        "        with open(csv_path, \"rb\") as f:\n",
        "            load_job = client.load_table_from_file(f, table_ref, job_config=job_config)\n",
        "\n",
        "        # Wait for completion; raises on job failure\n",
        "        load_job.result()\n",
        "\n",
        "        # Job may still have partial errors (within max_bad_records)\n",
        "        if load_job.errors:\n",
        "            print(f\"Completed with {len(load_job.errors)} load errors (tolerated by max_bad_records={MAX_BAD_RECORDS}).\")\n",
        "            for err in load_job.errors[:5]:\n",
        "                print(\"  -\", err)\n",
        "\n",
        "        table = client.get_table(table_ref)\n",
        "        print(f\"Loaded {table.num_rows} rows into {table.full_table_id}\")\n",
        "        summary.append((table_name, table.num_rows))\n",
        "\n",
        "    except (BadRequest, GoogleAPICallError, Exception) as e:\n",
        "        # Try to surface job-level error details if available\n",
        "        err_details = None\n",
        "        try:\n",
        "            if 'load_job' in locals() and load_job is not None:\n",
        "                if getattr(load_job, \"error_result\", None):\n",
        "                    err_details = load_job.error_result\n",
        "                elif getattr(load_job, \"errors\", None):\n",
        "                    err_details = load_job.errors[:5]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(f\"ERROR loading {table_name}: {e}\")\n",
        "        if err_details:\n",
        "            print(\"  Details:\", err_details)\n",
        "        failures.append((table_name, str(e)))\n",
        "\n",
        "print(\"\\n=== Load Summary ===\")\n",
        "for name, rows in summary:\n",
        "    print(f\"{name}: {rows} rows\")\n",
        "\n",
        "if failures:\n",
        "    print(\"\\n=== Failures ===\")\n",
        "    for name, msg in failures:\n",
        "        print(f\"{name}: {msg}\")\n",
        "else:\n",
        "    print(\"\\nNo failures 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX_z9YuP4qKm",
        "outputId": "4b1315bf-60ee-4631-db20-c4719e2f2bb1"
      },
      "id": "yX_z9YuP4qKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using data directory: fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24\n",
            "Dataset qwiklabs-gcp-01-e87a8593b193.fda_dataset exists.\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/acquisition_samples.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.acquisition_samples\n",
            "Loaded 7999 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.acquisition_samples\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/agricultural_samples.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.agricultural_samples\n",
            "Loaded 810 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.agricultural_samples\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food\n",
            "Completed with 80 load errors (tolerated by max_bad_records=100).\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55226 byte_offset_to_start_of_line: 4599840 column_index: 4 column_name: \"publication_date\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55232 byte_offset_to_start_of_line: 4600223 column_index: 4 column_name: \"publication_date\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55253 byte_offset_to_start_of_line: 4601733 column_index: 4 column_name: \"publication_date\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55261 byte_offset_to_start_of_line: 4602269 column_index: 4 column_name: \"publication_date\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55264 byte_offset_to_start_of_line: 4602464 column_index: 4 column_name: \"publication_date\" column_type: DATE value: \"7/19/2023\"'}\n",
            "Loaded 74095 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_attribute.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_attribute\n",
            "Loaded 7178 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_attribute\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_attribute_type.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_attribute_type\n",
            "Loaded 5 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_attribute_type\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_calorie_conversion_factor.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_calorie_conversion_factor\n",
            "Loaded 365 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_calorie_conversion_factor\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_category.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_category\n",
            "Loaded 28 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_category\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_component.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_component\n",
            "Loaded 3066 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_component\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_nutrient.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_nutrient\n",
            "Loaded 155243 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_nutrient\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_nutrient_conversion_factor.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_nutrient_conversion_factor\n",
            "Loaded 11476 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_nutrient_conversion_factor\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_portion.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_portion\n",
            "Loaded 10678 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_portion\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_protein_conversion_factor.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_protein_conversion_factor\n",
            "Loaded 341 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_protein_conversion_factor\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/food_update_log_entry.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.food_update_log_entry\n",
            "Completed with 80 load errors (tolerated by max_bad_records=100).\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55226 byte_offset_to_start_of_line: 3340950 column_index: 2 column_name: \"last_updated\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55232 byte_offset_to_start_of_line: 3341207 column_index: 2 column_name: \"last_updated\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55253 byte_offset_to_start_of_line: 3342276 column_index: 2 column_name: \"last_updated\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55261 byte_offset_to_start_of_line: 3342644 column_index: 2 column_name: \"last_updated\" column_type: DATE value: \"7/19/2023\"'}\n",
            "  - {'reason': 'invalid', 'message': 'Error while reading data, error message: Failed to parse input string \"7/19/2023\"; line_number: 55264 byte_offset_to_start_of_line: 3342776 column_index: 2 column_name: \"last_updated\" column_type: DATE value: \"7/19/2023\"'}\n",
            "Loaded 74095 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.food_update_log_entry\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/foundation_food.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.foundation_food\n",
            "Loaded 340 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.foundation_food\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/input_food.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.input_food\n",
            "Loaded 5676 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.input_food\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.lab_method\n",
            "Loaded 284 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.lab_method\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method_code.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.lab_method_code\n",
            "Loaded 193 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.lab_method_code\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/lab_method_nutrient.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.lab_method_nutrient\n",
            "Loaded 568 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.lab_method_nutrient\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/market_acquisition.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.market_acquisition\n",
            "Loaded 7215 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.market_acquisition\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/measure_unit.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.measure_unit\n",
            "Loaded 122 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.measure_unit\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/nutrient.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.nutrient\n",
            "Loaded 477 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.nutrient\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sample_food.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.sample_food\n",
            "Loaded 3717 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.sample_food\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sub_sample_food.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.sub_sample_food\n",
            "Loaded 62022 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.sub_sample_food\n",
            "\n",
            "Loading fooddata_csv/FoodData_Central_foundation_food_csv_2025-04-24/sub_sample_result.csv -> qwiklabs-gcp-01-e87a8593b193.fda_dataset.sub_sample_result\n",
            "Loaded 121234 rows into qwiklabs-gcp-01-e87a8593b193:fda_dataset.sub_sample_result\n",
            "\n",
            "=== Load Summary ===\n",
            "acquisition_samples: 7999 rows\n",
            "agricultural_samples: 810 rows\n",
            "food: 74095 rows\n",
            "food_attribute: 7178 rows\n",
            "food_attribute_type: 5 rows\n",
            "food_calorie_conversion_factor: 365 rows\n",
            "food_category: 28 rows\n",
            "food_component: 3066 rows\n",
            "food_nutrient: 155243 rows\n",
            "food_nutrient_conversion_factor: 11476 rows\n",
            "food_portion: 10678 rows\n",
            "food_protein_conversion_factor: 341 rows\n",
            "food_update_log_entry: 74095 rows\n",
            "foundation_food: 340 rows\n",
            "input_food: 5676 rows\n",
            "lab_method: 284 rows\n",
            "lab_method_code: 193 rows\n",
            "lab_method_nutrient: 568 rows\n",
            "market_acquisition: 7215 rows\n",
            "measure_unit: 122 rows\n",
            "nutrient: 477 rows\n",
            "sample_food: 3717 rows\n",
            "sub_sample_food: 62022 rows\n",
            "sub_sample_result: 121234 rows\n",
            "\n",
            "No failures 🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Authenticate to BQ\n",
        "\n",
        "import google.auth\n",
        "from google.cloud import bigquery\n",
        "creds, proj = google.auth.default()\n",
        "print(\"ADC project:\", proj)\n",
        "\n",
        "# This just tests to ensure we are authenticated to BQ\n",
        "bq = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
        "bq.query(\"SELECT 1\").result()\n",
        "print(\"BigQuery query OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi_HQeTKGDy3",
        "outputId": "a98d33d8-01f3-47e4-94b8-fa0a6f32af7a"
      },
      "id": "wi_HQeTKGDy3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADC project: qwiklabs-gcp-01-e87a8593b193\n",
            "BigQuery query OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title This just tests to ensure we are authenticate with Gemini.\n",
        "\n",
        "# Quick sanity check using google-genai directly:\n",
        "from google import genai\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=\"hello\")\n",
        "print(resp.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Ntd9ILHrb4",
        "outputId": "e432dc2b-a371-43ef-8c5a-1353bc50aedb"
      },
      "id": "J-Ntd9ILHrb4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ADK Imports\n",
        "import asyncio\n",
        "import os\n",
        "import google.auth\n",
        "from google.genai import types\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools.bigquery import BigQueryCredentialsConfig, BigQueryToolset\n",
        "from google.adk.tools.bigquery.config import BigQueryToolConfig, WriteMode\n",
        "from google.adk.tools import google_search   # built-in Google Search tool\n"
      ],
      "metadata": {
        "id": "1-HYJQb1WEil"
      },
      "id": "1-HYJQb1WEil",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build the BigQuery Agent. Uses the BigQuery tool to access the BQ Dataset created earlier\n",
        "\n",
        "\n",
        "# Uses Application Default Credentials for BigQuery (gcloud or service account).\n",
        "adc, _ = google.auth.default()\n",
        "bq_credentials = BigQueryCredentialsConfig(credentials=adc)\n",
        "\n",
        "# Read-only tool config (blocks DDL/DML). You can change to WriteMode.ALLOWED later if needed.\n",
        "bq_tool_cfg = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n",
        "\n",
        "# Instantiate the BigQuery toolset\n",
        "bq_tools = BigQueryToolset(\n",
        "    credentials_config=bq_credentials,\n",
        "    bigquery_tool_config=bq_tool_cfg\n",
        ")\n",
        "\n",
        "DB_SCHEMA = \"\"\"\n",
        "\n",
        "[{\n",
        "  \"table_name\": \"lab_method_nutrient\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"lab_method_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"nutrient_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_update_log_entry\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"last_updated\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"input_food\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_of_input_food\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"seq_num\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"amount\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"ingredient_code\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"ingredient_description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"unit\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"portion_code\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"portion_description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"gram_weight\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"retention_code\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"sub_sample_food\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id_of_sample_food\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"data_type\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"food_category_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"publication_date\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"foundation_food\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"NDB_number\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"footnote\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"market_acquisition\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"brand_description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"expiration_date\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }, {\n",
        "    \"column_name\": \"label_weight\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"location\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"acquisition_date\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }, {\n",
        "    \"column_name\": \"sales_type\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"sample_lot_nbr\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"sell_by_date\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }, {\n",
        "    \"column_name\": \"store_city\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"store_name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"store_state\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"upc_code\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_protein_conversion_factor\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"food_nutrient_conversion_factor_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"value\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"lab_method_code\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"lab_method_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"code\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_nutrient_conversion_factor\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_calorie_conversion_factor\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"food_nutrient_conversion_factor_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"protein_value\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fat_value\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"carbohydrate_value\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_portion\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"seq_num\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"amount\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"measure_unit_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"portion_description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"modifier\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"gram_weight\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"data_points\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"footnote\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"min_year_acquired\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"sample_food\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"lab_method\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"technique\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"nutrient\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"unit_name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"nutrient_nbr\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"rank\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_nutrient\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"nutrient_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"amount\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"data_points\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"derivation_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"min\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"max\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"median\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"footnote\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"min_year_acquired\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"measure_unit\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"acquisition_samples\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id_of_sample_food\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id_of_acquisition_food\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"agricultural_samples\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"acquisition_date\",\n",
        "    \"data_type\": \"DATE\"\n",
        "  }, {\n",
        "    \"column_name\": \"market_class\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"treatment\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"state\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"sub_sample_result\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"food_nutrient_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"adjusted_amount\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"lab_method_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"nutrient_name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_attribute_type\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_category\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"code\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"description\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_attribute\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"seq_num\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"food_attribute_type_id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"value\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }]\n",
        "}, {\n",
        "  \"table_name\": \"food_component\",\n",
        "  \"fields\": [{\n",
        "    \"column_name\": \"id\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"fdc_id\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"name\",\n",
        "    \"data_type\": \"STRING\"\n",
        "  }, {\n",
        "    \"column_name\": \"pct_weight\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"is_refuse\",\n",
        "    \"data_type\": \"BOOL\"\n",
        "  }, {\n",
        "    \"column_name\": \"gram_weight\",\n",
        "    \"data_type\": \"FLOAT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"data_points\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }, {\n",
        "    \"column_name\": \"min_year_acqured\",\n",
        "    \"data_type\": \"INT64\"\n",
        "  }]\n",
        "}]\n",
        "\"\"\"\n",
        "\n",
        "# Instruct the agent to **only** use your dataset\n",
        "INSTR = f\"\"\"\n",
        "You are a data analysis agent with access to BigQuery tools.\n",
        "The dataset you have access to contains information from the USDA about foods and nutrician information.\n",
        "Only query the dataset `{PROJECT_ID}.{DATASET_NAME}`.\n",
        "Fully qualify every table as `{PROJECT_ID}.{DATASET_NAME}.<table>`.\n",
        "Never perform DDL/DML; SELECT-only. Return the SQL you ran along with a concise answer.\n",
        "Here is the database schema, please study it {DB_SCHEMA}\n",
        "\"\"\"\n",
        "\n",
        "usda_bigquery_agent = Agent(\n",
        "    model=MODEL,         # Works with ADK; requires a Gemini API key or Vertex AI setup\n",
        "    name=\"usda_food_information_bigquery_agent\",\n",
        "    description=\"\"\"Analyzes tables in a BigQuery dataset that contains food information from the USDA. Tables.\"\"\",\n",
        "    instruction=INSTR,\n",
        "    tools=[bq_tools],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rceGEU8J-A8z",
        "outputId": "163f297e-2482-4ceb-d207-7bc4b7fc4538"
      },
      "id": "rceGEU8J-A8z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1305342453.py:6: UserWarning: [EXPERIMENTAL] BigQueryCredentialsConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  bq_credentials = BigQueryCredentialsConfig(credentials=adc)\n",
            "/usr/local/lib/python3.11/dist-packages/google/adk/utils/feature_decorator.py:87: UserWarning: [EXPERIMENTAL] BaseGoogleCredentialsConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  return orig_init(self, *args, **kwargs)\n",
            "/tmp/ipython-input-1305342453.py:9: UserWarning: [EXPERIMENTAL] BigQueryToolConfig: Config defaults may have breaking change in the future.\n",
            "  bq_tool_cfg = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n",
            "/tmp/ipython-input-1305342453.py:12: UserWarning: [EXPERIMENTAL] BigQueryToolset: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  bq_tools = BigQueryToolset(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the Allergy Research Agent\n",
        "import sys, subprocess, importlib, asyncio, re\n",
        "from urllib.parse import urlparse, urljoin\n",
        "import httpx\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# ---- Configure the site you want to use as the sole information source ----\n",
        "SITE_URL = \"http://www.allergenonline.org/\"     # <-- change me\n",
        "_ALLOWED = urlparse(SITE_URL).netloc.lower()\n",
        "\n",
        "def fetch_url(url: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetch and return cleaned text content from a URL within the allowed domain.\n",
        "\n",
        "    Args:\n",
        "        url (str): HTTP/HTTPS URL to fetch.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "          \"url\": <final-url>,\n",
        "          \"title\": <page title or None>,\n",
        "          \"text\": <cleaned text (truncated)>,\n",
        "          \"chars\": <len(text)>\n",
        "        }\n",
        "\n",
        "    Notes:\n",
        "      - Only allows URLs on the configured site/domain.\n",
        "      - Strips scripts/styles and collapses whitespace.\n",
        "      - Truncates very large pages to keep context small.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        u = url.strip()\n",
        "        # Normalize relative links against base, just in case\n",
        "        if u.startswith(\"/\"):\n",
        "            u = urljoin(SITE_URL, u)\n",
        "\n",
        "        parsed = urlparse(u)\n",
        "        if parsed.scheme not in {\"http\", \"https\"}:\n",
        "            return {\"status\": \"error\", \"error_message\": \"Only http/https URLs are allowed.\"}\n",
        "        if not parsed.netloc.lower().endswith(_ALLOWED):\n",
        "            return {\"status\": \"error\", \"error_message\": f\"URL not in allowed domain: {_ALLOWED}\"}\n",
        "\n",
        "        # Fetch with sane limits\n",
        "        with httpx.Client(follow_redirects=True, timeout=20) as client:\n",
        "            resp = client.get(u, headers={\"User-Agent\": \"adk-site-agent/1.0\"})\n",
        "            resp.raise_for_status()\n",
        "            ctype = resp.headers.get(\"content-type\", \"\").lower()\n",
        "            if \"text/html\" not in ctype and \"application/xhtml\" not in ctype:\n",
        "                return {\"status\": \"error\", \"error_message\": f\"Unsupported content-type: {ctype}\"}\n",
        "\n",
        "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "            # Remove noise\n",
        "            for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "                tag.decompose()\n",
        "            title = (soup.title.string.strip() if soup.title and soup.title.string else None)\n",
        "            text = re.sub(r\"\\s+\", \" \", soup.get_text(separator=\" \", strip=True))\n",
        "            MAX_CHARS = 20000\n",
        "            if len(text) > MAX_CHARS:\n",
        "                text = text[:MAX_CHARS] + \" ... [truncated]\"\n",
        "            return {\"status\": \"success\", \"url\": str(resp.url), \"title\": title, \"text\": text, \"chars\": len(text)}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"error_message\": str(e)}\n",
        "\n",
        "# ---- Agent that uses Google Search (site-restricted) + fetch_url ----\n",
        "INSTR = f\"\"\"\n",
        "You are a site-scoped research agent.\n",
        "Only use Google Search constrained to the domain {_ALLOWED} by prefixing queries with 'site:{_ALLOWED}'.\n",
        "You research information about food alergens and food health information.\n",
        "When you identify promising results, call fetch_url(url) to open and read the page content.\n",
        "Cite the specific URLs you used in your final answer. Do not use sources outside {_ALLOWED}.\n",
        "\"\"\"\n",
        "\n",
        "allergen_research_agent = Agent(\n",
        "    model=MODEL,   # or your preferred Gemini model\n",
        "    name=\"site_research_agent\",\n",
        "    description=f\"Answers questions using only content from {_ALLOWED}.\",\n",
        "    instruction=INSTR,\n",
        "    tools=[google_search, fetch_url],  # built-in search + custom fetcher\n",
        ")\n"
      ],
      "metadata": {
        "id": "rxnnIiwfWULG"
      },
      "id": "rxnnIiwfWULG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the Main (root) Agent\n",
        "MAIN_AGENT_INSTRUCTIONS=\"\"\"\n",
        "You are a friendly food and nutrician agent.\n",
        "Answer questions related to food, nutrician, allergies, dietary health, and other inquiries related to thise things.\n",
        "You have 2 helper agents.\n",
        "- The usda_bigquery_agent has access to a large database from the USDA containing all sorts to food-related information.\n",
        "- The allergen_research agent can search the Allergen Online web site for allergy-related information.\n",
        "\"\"\"\n",
        "\n",
        "main_agent = Agent(\n",
        "    name=\"main_agent\",\n",
        "    model=MODEL,\n",
        "    description=\"Provides Answers to Users Food and Allergy Questions.\",\n",
        "    instruction=MAIN_AGENT_INSTRUCTIONS,\n",
        "    sub_agents=[usda_bigquery_agent, allergen_research_agent],\n",
        ")"
      ],
      "metadata": {
        "id": "inSY3xgPdo_s"
      },
      "id": "inSY3xgPdo_s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the Runner that uses our root agent\n",
        "\n",
        "# --- Session Management ---\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Define constants for identifying the interaction context\n",
        "APP_NAME = \"usda_food_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
        "\n",
        "# Create the specific session where the conversation will happen\n",
        "session = await session_service.create_session(\n",
        "    app_name=APP_NAME,\n",
        "    user_id=USER_ID,\n",
        "    session_id=SESSION_ID\n",
        ")\n",
        "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "\n",
        "# --- Runner ---\n",
        "# Key Concept: Runner orchestrates the agent execution loop.\n",
        "runner = Runner(\n",
        "    agent=main_agent, # The agent we want to run\n",
        "    app_name=APP_NAME,   # Associates runs with our app\n",
        "    session_service=session_service # Uses our session manager\n",
        ")\n",
        "print(f\"Runner created for agent '{runner.agent.name}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdTuQPLSnezJ",
        "outputId": "4eb72b82-93a7-4a90-990d-22a8c254e14c"
      },
      "id": "rdTuQPLSnezJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session created: App='usda_food_app', User='user_1', Session='session_001'\n",
            "Runner created for agent 'main_agent'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Agent Interaction Function\n",
        "\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
        "\n",
        "  # Prepare the user's message in ADK format\n",
        "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
        "\n",
        "  # Key Concept: run_async executes the agent logic and yields Events.\n",
        "  # We iterate through events to find the final answer.\n",
        "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "      # You can uncomment the line below to see *all* events during execution\n",
        "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
        "\n",
        "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
        "      if event.is_final_response():\n",
        "          if event.content and event.content.parts:\n",
        "             # Assuming text response in the first part\n",
        "             final_response_text = event.content.parts[0].text\n",
        "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
        "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "          # Add more checks here if needed (e.g., specific error codes)\n",
        "          break # Stop processing events once the final response is found\n",
        "\n",
        "  return final_response_text"
      ],
      "metadata": {
        "id": "47j1AmhOVfuC"
      },
      "id": "47j1AmhOVfuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run the Initial Conversation\n",
        "\n",
        "questions = [\n",
        "    # \"List all tables in the dataset.\",\n",
        "    # \"Top 10 foods by protein per 100g from the table `food_nutrient` joined with `nutrient`.\",\n",
        "    # \"How many rows are in `food`?\",\n",
        "    \"Give me a dinner recommendation for someone with allergies to dairy and nuts. Include a meat, starch, and vegetable\"\n",
        "    ]\n",
        "\n",
        "# We need an async function to await our interaction helper\n",
        "async def run_conversation():\n",
        "  for q in questions:\n",
        "    response = await call_agent_async(query=q,runner=runner,user_id=USER_ID,session_id=SESSION_ID)\n",
        "    print(\"-----------------------------\")\n",
        "    print(f\"User: {q}\")\n",
        "    print(f\"Model: {response}\")\n",
        "    print(\"-----------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
        "await run_conversation()\n",
        "\n",
        "# --- OR ---\n",
        "\n",
        "# Uncomment the following lines if running as a standard Python script (.py file):\n",
        "# import asyncio\n",
        "# if __name__ == \"__main__\":\n",
        "#     try:\n",
        "#         asyncio.run(run_conversation())\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZvlTXBCoO3z",
        "outputId": "9b4d5bd1-11a0-440a-c8e0-8460aa1204b5"
      },
      "id": "qZvlTXBCoO3z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "User: Give me a dinner recommendation for someone with allergies to dairy and nuts. Include a meat, starch, and vegetable\n",
            "Model: Here's a dinner recommendation for someone with dairy and nut allergies:\n",
            "\n",
            "*   **Meat:** Grilled Chicken Breast\n",
            "*   **Starch:** Roasted Sweet Potatoes\n",
            "*   **Vegetable:** Steamed Green Beans\n",
            "\n",
            "This meal is naturally free of dairy and nuts. When preparing, ensure to use cooking oils that are not nut-based (like olive oil or avocado oil) and check any seasonings or marinades to confirm they are also free from dairy and nuts. Always be mindful of cross-contamination in the kitchen when dealing with severe allergies.\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Unclosed client session\n",
            "client_session: <aiohttp.client.ClientSession object at 0x7f52fd8d3c50>\n",
            "ERROR:asyncio:Unclosed connector\n",
            "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7f52fd9b6430>, 16609.651991653)])']\n",
            "connector: <aiohttp.connector.TCPConnector object at 0x7f52fd9858d0>\n",
            "ERROR:asyncio:Unclosed client session\n",
            "client_session: <aiohttp.client.ClientSession object at 0x7f52fdb4ec10>\n",
            "ERROR:asyncio:Unclosed connector\n",
            "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7f52fd9b6270>, 16606.919531088)])']\n",
            "connector: <aiohttp.connector.TCPConnector object at 0x7f52fe503e90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run a Chat with the Agent.\n",
        "await chat_with_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LawbanP1KwyP",
        "outputId": "8cba6e99-7f9d-4b9b-f9e3-22fc8c520d91"
      },
      "id": "LawbanP1KwyP",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat started. Type 'exit' (or press Enter on a blank line) to stop.\n",
            "\n",
            "You: Hi, can you tell me the tables in the FDA dataset?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agent: The tables in the FDA dataset are: acquisition_samples, agricultural_samples, food, food_attribute, food_attribute_type, food_calorie_conversion_factor, food_category, food_component, food_nutrient, food_nutrient_conversion_factor, food_portion, food_protein_conversion_factor, food_update_log_entry, foundation_food, input_food, lab_method, lab_method_code, lab_method_nutrient, market_acquisition, measure_unit, nutrient, sample_food, sub_sample_food, and sub_sample_result.\n",
            "\n",
            "You: What foods high in protien?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agent: Here are some foods that are high in protein, based on the data in the FDA dataset:\n",
            "\n",
            "| fdc_id  | name     | total_protein |\n",
            "|---------|----------|---------------|\n",
            "| 323793  | Protein  | 79.9          |\n",
            "| 1104705 | Protein  | 51.1          |\n",
            "| 329490  | Protein  | 48.1          |\n",
            "| 749420  | Protein  | 40.9          |\n",
            "| 1104766 | Protein  | 38.6          |\n",
            "| 329716  | Protein  | 34.2          |\n",
            "| 331960  | Protein  | 32.1          |\n",
            "| 335969  | Protein  | 31.6          |\n",
            "| 335595  | Protein  | 30.8          |\n",
            "| 335972  | Protein  | 30.5          |\n",
            "\n",
            "Please note that the fdc_id is a unique identifier for the food in the database. To find out what these foods actually are, you would need to look them up in the `food` table using their `fdc_id`.\n",
            "\n",
            "\n",
            "You: What foods are high in sugar content?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agent: Here are some foods that are high in sugar, based on the data in the FDA dataset:\n",
            "\n",
            "| fdc_id  | name           | total_sugar |\n",
            "|---------|----------------|-------------|\n",
            "| 334247  | Sugars, Total  | 99.8        |\n",
            "| 746784  | Sugars, Total  | 99.8        |\n",
            "| 746768  | Sugars, Total  | 47.9        |\n",
            "| 326905  | Sugars, Total  | 47.9        |\n",
            "| 333008  | Sugars, Total  | 34.8        |\n",
            "| 747693  | Sugars, Total  | 21.8        |\n",
            "| 2710843 | Sugars, Total  | 19.16633    |\n",
            "| 2263890 | Sugars, Total  | 17.341      |\n",
            "| 2346412 | Sugars, Total  | 17.341      |\n",
            "| 2346413 | Sugars, Total  | 16.133      |\n",
            "\n",
            "Please note that the fdc_id is a unique identifier for the food in the database. To find out what these foods actually are, you would need to look them up in the `food` table using their `fdc_id`.\n",
            "\n",
            "\n",
            "You: Can you show me high protein foods along with their names and provide a brief description?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Agent: Here are some high-protein foods, their descriptions, and protein content per 100g:\n",
            "\n",
            "| Food Description                                                                               | fdc_id  | protein_per_100g |\n",
            "|------------------------------------------------------------------------------------------------|---------|-------------------|\n",
            "| Egg, white, dried                                                                              | 323793  | 79.9              |\n",
            "| Flour, soy, defatted                                                                           | 1104705 | 51.1              |\n",
            "| Egg, whole, dried                                                                              | 329490  | 48.1              |\n",
            "| Pork, cured, bacon, cooked, restaurant                                                         | 749420  | 40.9              |\n",
            "| Flour, soy, full-fat                                                                           | 1104766 | 38.6              |\n",
            "| Egg, yolk, dried                                                                               | 329716  | 34.2              |\n",
            "| Chicken, broiler or fryers, breast, skinless, boneless, meat only, cooked, braised             | 331960  | 32.1              |\n",
            "| Beans, Dry, Great Northern, 446 (0% moisture)                                                  | 335969  | 31.6              |\n",
            "| Beans, Dry, Pinto, 468 (0% moisture)                                                            | 335595  | 30.8              |\n",
            "| Beans, Dry, Great Northern, 579 (0% moisture)                                                  | 335972  | 30.5              |\n",
            "\n",
            "\n",
            "You: quit\n",
            "Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deploy to Agent Engine\n",
        "from vertexai import agent_engines\n",
        "\n",
        "# Wrap the agent in an AdkApp object\n",
        "app = agent_engines.AdkApp(\n",
        "    agent=main_agent,\n",
        "    enable_tracing=True,\n",
        ")\n",
        "\n",
        "remote_app = agent_engines.create(\n",
        "    agent_engine=app,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[adk,agent_engines]\",\n",
        "        \"google-auth\",\n",
        "        \"google-genai\",\n",
        "        \"httpx\",\n",
        "        \"beautifulsoup4\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Deployment finished!\")\n",
        "print(f\"Resource Name: {remote_app.resource_name}\")\n",
        "# Resource Name: \"projects/{PROJECT_NUMBER}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc571cazq6n_",
        "outputId": "02fece17-52a0-41c1-d363-ce1cf59efa9f"
      },
      "id": "qc571cazq6n_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.agent_engines:Identified the following requirements: {'pydantic': '2.11.7', 'google-cloud-aiplatform': '1.114.0', 'cloudpickle': '3.1.1'}\n",
            "WARNING:vertexai.agent_engines:The following requirements are missing: {'pydantic', 'cloudpickle'}\n",
            "INFO:vertexai.agent_engines:The following requirements are appended: {'cloudpickle==3.1.1', 'pydantic==2.11.7'}\n",
            "INFO:vertexai.agent_engines:The final list of requirements: ['google-cloud-aiplatform[adk,agent_engines]', 'google-auth', 'google-genai', 'httpx', 'beautifulsoup4', 'cloudpickle==3.1.1', 'pydantic==2.11.7']\n",
            "INFO:vertexai.agent_engines:Using bucket dsf345gjt\n",
            "INFO:vertexai.agent_engines:Wrote to gs://dsf345gjt/agent_engine/agent_engine.pkl\n",
            "INFO:vertexai.agent_engines:Writing to gs://dsf345gjt/agent_engine/requirements.txt\n",
            "INFO:vertexai.agent_engines:Creating in-memory tarfile of extra_packages\n",
            "INFO:vertexai.agent_engines:Writing to gs://dsf345gjt/agent_engine/dependencies.tar.gz\n",
            "WARNING:vertexai.agent_engines:failed to generate schema for async_add_session_to_memory: `async_add_session_to_memory` is not fully defined; you should define `Session`, then call `async_add_session_to_memory.model_rebuild()`.\n",
            "\n",
            "For further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined\n",
            "INFO:vertexai.agent_engines:Creating AgentEngine\n",
            "INFO:vertexai.agent_engines:Create AgentEngine backing LRO: projects/569345689354/locations/us-central1/reasoningEngines/412189317067177984/operations/9142816746942496768\n",
            "INFO:vertexai.agent_engines:View progress and logs at https://console.cloud.google.com/logs/query?project=qwiklabs-gcp-01-e87a8593b193\n",
            "INFO:vertexai.agent_engines:AgentEngine created. Resource name: projects/569345689354/locations/us-central1/reasoningEngines/412189317067177984\n",
            "INFO:vertexai.agent_engines:To use this AgentEngine in another session:\n",
            "INFO:vertexai.agent_engines:agent_engine = vertexai.agent_engines.get('projects/569345689354/locations/us-central1/reasoningEngines/412189317067177984')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deployment finished!\n",
            "Resource Name: projects/569345689354/locations/us-central1/reasoningEngines/412189317067177984\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "The Medical Diet Navigator Agent"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}